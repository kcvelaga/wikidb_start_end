{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b0d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wmfdata import mariadb\n",
    "from wmfdata.utils import sql_tuple\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f6d1d",
   "metadata": {},
   "source": [
    "[canonical-data](https://github.com/wikimedia-research/canonical-data/blob/master/wiki/wikis.tsv) is the best available and accessible source to gather data for list of wikis, their visilibity and status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67cf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_wikis = pd.read_csv('https://raw.githubusercontent.com/wikimedia-research/canonical-data/master/wiki/wikis.tsv', sep='\\t')\n",
    "\n",
    "# for the scope of this analysis, we are only concerned about publicly visible and editable projects\n",
    "public_wikis = cd_wikis.query(\"\"\"(visibility == 'public') & (editability == 'public')\"\"\").reset_index(drop=True)\n",
    "\n",
    "# further limiting to content projects: with this, test wikis, organizational wikis, wikimania wikis etc. will be dropped\n",
    "content_db_groups = ['commons', 'wikibooks', 'wikidata', 'wikinews', 'wikipedia', 'wikiquote', 'wikisource', 'wikiversity', 'wikivoyage', 'wiktionary']\n",
    "public_content_wikis = public_wikis.query(\"\"\"database_group == @content_db_groups\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b825e4c",
   "metadata": {},
   "source": [
    "## Gather git blame data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84715816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mediawiki-config'...\n",
      "remote: Counting objects: 9, done\u001b[K\n",
      "remote: Finding sources: 100% (9/9)\u001b[K\u001b[K\n",
      "remote: Getting sizes: 100% (6/6)\u001b[K\u001b[K\n",
      "remote: Compressing objects: 100% (121267/121267)\u001b[K\u001b[K\n",
      "remote: Total 141772 (delta 1), reused 141766 (delta 1)\u001b[K3 MiB/s   \n",
      "Receiving objects: 100% (141772/141772), 171.26 MiB | 39.88 MiB/s, done.\n",
      "Resolving deltas: 100% (99601/99601), done.\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# get the blame data into text files in git_blame_data directory\n",
    "# for all, closed, private, and fishbowl\n",
    "!chmod +x get_blame.sh\n",
    "!./get_blame.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ffcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the git_blame_data from txt to dict, and to Pandas Dataframe\n",
    "blame_data = {}\n",
    "\n",
    "for category in ['all', 'closed']:\n",
    "    \n",
    "    blame_data[category] = {}\n",
    "    \n",
    "    with open(f'git_blame_data/{category}.txt') as blame_file:\n",
    "        lines = blame_file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'Do not edit it' in line:\n",
    "            pass\n",
    "        else:\n",
    "            wiki_db = re.sub('.*\\)', '', line).strip()\n",
    "            dt = re.findall('\\d{4}-\\d{2}-\\d{2}', line)[0]\n",
    "            blame_data[category][wiki_db] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661f0ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database_code</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>database_group</th>\n",
       "      <th>language_code</th>\n",
       "      <th>language_name</th>\n",
       "      <th>status</th>\n",
       "      <th>visibility</th>\n",
       "      <th>editability</th>\n",
       "      <th>english_name</th>\n",
       "      <th>git_created_dt</th>\n",
       "      <th>git_closed_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aawiki</td>\n",
       "      <td>aa.wikipedia.org</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>aa</td>\n",
       "      <td>Afar</td>\n",
       "      <td>closed</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>Afar Wikipedia</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>2012-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aawikibooks</td>\n",
       "      <td>aa.wikibooks.org</td>\n",
       "      <td>wikibooks</td>\n",
       "      <td>aa</td>\n",
       "      <td>Afar</td>\n",
       "      <td>closed</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>Afar Wikibooks</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>2012-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aawiktionary</td>\n",
       "      <td>aa.wiktionary.org</td>\n",
       "      <td>wiktionary</td>\n",
       "      <td>aa</td>\n",
       "      <td>Afar</td>\n",
       "      <td>closed</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>Afar Wiktionary</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>2012-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abwiki</td>\n",
       "      <td>ab.wikipedia.org</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>ab</td>\n",
       "      <td>Abkhazian</td>\n",
       "      <td>open</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>Abkhazian Wikipedia</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abwiktionary</td>\n",
       "      <td>ab.wiktionary.org</td>\n",
       "      <td>wiktionary</td>\n",
       "      <td>ab</td>\n",
       "      <td>Abkhazian</td>\n",
       "      <td>closed</td>\n",
       "      <td>public</td>\n",
       "      <td>public</td>\n",
       "      <td>Abkhazian Wiktionary</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>2012-02-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database_code        domain_name database_group language_code language_name  \\\n",
       "0        aawiki   aa.wikipedia.org      wikipedia            aa          Afar   \n",
       "1   aawikibooks   aa.wikibooks.org      wikibooks            aa          Afar   \n",
       "2  aawiktionary  aa.wiktionary.org     wiktionary            aa          Afar   \n",
       "3        abwiki   ab.wikipedia.org      wikipedia            ab     Abkhazian   \n",
       "4  abwiktionary  ab.wiktionary.org     wiktionary            ab     Abkhazian   \n",
       "\n",
       "   status visibility editability          english_name git_created_dt  \\\n",
       "0  closed     public      public        Afar Wikipedia     2012-02-24   \n",
       "1  closed     public      public        Afar Wikibooks     2012-02-24   \n",
       "2  closed     public      public       Afar Wiktionary     2012-02-24   \n",
       "3    open     public      public   Abkhazian Wikipedia     2012-02-24   \n",
       "4  closed     public      public  Abkhazian Wiktionary     2012-02-24   \n",
       "\n",
       "  git_closed_dt  \n",
       "0    2012-02-24  \n",
       "1    2012-02-24  \n",
       "2    2012-02-24  \n",
       "3           NaT  \n",
       "4    2012-02-24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict to dataframe and rename columns\n",
    "blame_data_df = (pd.DataFrame(blame_data)\n",
    "                 .reset_index()\n",
    "                 .rename({'index': 'database_code', 'all': 'git_created_dt', 'closed': 'git_closed_dt'}, axis=1))\n",
    "\n",
    "# combine git blame data with list of content dbs\n",
    "public_content_wikis = pd.merge(public_content_wikis, blame_data_df, on='database_code', how='left')\n",
    "\n",
    "# covert required columns to datatime format\n",
    "public_content_wikis['git_created_dt'] = pd.to_datetime(public_content_wikis['git_created_dt'], yearfirst=True, errors='coerce')\n",
    "public_content_wikis['git_closed_dt'] = pd.to_datetime(public_content_wikis['git_closed_dt'], yearfirst=True, errors='coerce')\n",
    "\n",
    "public_content_wikis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112dfbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation:\n",
      " 2012-02-24    695\n",
      "2012-05-08     72\n",
      "2012-11-06      8\n",
      "Name: git_created_dt, dtype: int64 \n",
      "\n",
      "closed:\n",
      " 2012-02-24    89\n",
      "2012-05-16     5\n",
      "2013-07-23     2\n",
      "Name: git_closed_dt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frequency of dates when a project was added to mediawiki_config files\n",
    "print('creation:\\n', public_content_wikis.git_created_dt.value_counts().head(3), '\\n')\n",
    "print('closed:\\n', public_content_wikis.git_closed_dt.value_counts().head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de773c",
   "metadata": {},
   "source": [
    "## wiki creation date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d5711",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7118bb88-42b0-41ae-aef6-e9a2faa32043",
   "metadata": {},
   "source": [
    "### 2001 to mid-2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ca1f3a-0a92-48f9-8b68-3cc997e10aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikis having their git date recorded on (or before) 24 February 2012\n",
    "pre2012 = public_content_wikis[public_content_wikis['git_created_dt'] <= datetime(2012, 2, 24)].reset_index(drop=True)\n",
    "\n",
    "# list of wikis graduated from incubator until 2012 (this is a manually created flat file based on: https://incubator.wikimedia.org/wiki/Incubator:Site_creation_log)\n",
    "incubator_pre2012_logs = pd.read_csv('incubator_logs/incubator_site_creation_log_pre2012.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cea51-0453-45af-a116-02a9d4d7ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incubator site logs from 2006 to 2010 \n",
    "incubator_200610_logs = pd.read_csv('incubator_site_creation_log_2006-2010.csv')\n",
    "incbator_200610_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a7662-d286-4106-b6e4-821783692c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikis_200610 = incubator_pre2012_logs.query(\"\"\"domain_name != @incbator_200610_logs.domain_name.values.tolist()\"\"\")\n",
    "wikis_200610.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b9948-73ed-490c-8cfd-ce23f9879423",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_incubator_creations = pre2012_wikis.query(\"\"\"domain_name != @incubator_pre2012_logs.domain_name.values.tolist()\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a02776-cf8b-4dc3-91e4-ca20411be4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_incubator_creations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e348c-7de1-4238-9b6a-912f7060d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rev_date = wmf.mariadb.run(\"\"\"SELECT MIN(rev_timestamp) AS min_rev_timestamp FROM revision\"\"\", non_incubator_creations['database_code'].values.tolist())\n",
    "min_rev_date['database_code'] = non_incubator_creations['database_code'].values.tolist()\n",
    "min_rev_date['min_rev_timestamp'] = pd.to_datetime(min_rev_date['min_rev_timestamp'], yearfirst=True, errors='coerce')\n",
    "min_rev_date['min_rev_timestamp'] = min_rev_date['min_rev_timestamp'].apply(lambda x:x.date())\n",
    "min_rev_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662afe7d-2c4b-4183-9c66-68a98e9d84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_messages(year, month):\n",
    "    url = f'https://lists.wikimedia.org/hyperkitty/list/newprojects@lists.wikimedia.org/{year}/{month}/'\n",
    "    result = requests.get(url)\n",
    "    page_content = BeautifulSoup(result.content, 'html.parser')\n",
    "    creation_dts = {}\n",
    "    for thread in page_content.find_all('div', {'class': 'thread-email row'}):\n",
    "        wiki_db = thread.find('span', class_='thread-title').text.replace('New wiki: ', '').strip()\n",
    "        date = thread.find('div', class_='threa-date').get('title')\n",
    "        date = datetime.strptime(date, '%A, %d %B %Y %H:%M:%S').date()\n",
    "        creation_dts[wiki_db] = date\n",
    "    return creation_dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f36734-cd43-4cf8-b34e-f5782aadbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_dts = {}\n",
    "for year in range(2010, 2012+1):\n",
    "    for month in range(1, 12+1):\n",
    "        output = extract_messages(year, month)\n",
    "        creation_dts = creation_dts | output\n",
    "\n",
    "creation_dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df329653-29f3-4e4a-a583-119c07b37375",
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_dt_201012 = pd.DataFrame(creation_dts.values(), index=creation_dts.keys(), columns=['date']).reset_index().rename({'index': 'database_code'}, axis=1)\n",
    "creation_dt_201012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da105f3d-75de-4964-9741-380afea659b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in creation_dt_201012.index:\n",
    "    db_code = creation_dt_201012.loc[i, 'database_code']\n",
    "    \n",
    "    if re.search('\\d{2}:\\d{2}:\\d{2}', db_code):\n",
    "        creation_dt_201012.drop(i, axis=0, inplace=True)\n",
    "    \n",
    "    if re.search('.*..*,.*', db_code):\n",
    "        dbs = db_code.split(':')[1].split(',')\n",
    "        df = pd.DataFrame([i.strip() for i in dbs],  columns = ['database_code'])\n",
    "        df['date'] = creation_dt_201012.loc[i, 'date']\n",
    "        creation_dt_201012.drop(i, axis=0, inplace=True)\n",
    "        creation_dt_201012 = pd.concat([creation_dt_201012, df], ignore_index=True)\n",
    "\n",
    "creation_dt_201012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce4a26-cdda-4bd1-9bf1-46cf47feaa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_dt_201012 = pd.merge(creation_dt_201012, cd_wikis[['domain_name', 'database_code']], on='database_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccecd3f-4f99-4490-8eb3-42869efb552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "incubator201012 = incubator_pre2012_logs.query(\"\"\"domain_name != @incbator_200610_logs.domain_name.values.tolist()\"\"\")\n",
    "incubator201012 = pd.merge(incubator201012, creation_dt_201012, on='domain_name', how='left').drop('database_code', axis=1)\n",
    "incubator201012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c7a3a-75c0-442b-b420-c5ea6196eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates = {\n",
    "    'nso.wikipedia.org': datetime(2011, 10, 29).date(),\n",
    "    'or.wiktionary.org': datetime(2011, 9, 28).date()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d127784-f2f5-444e-a0c0-dbee07d320b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in incubator201012[incubator201012.date.isna()].index:\n",
    "    incubator201012.loc[i, 'date'] = missing_dates[incubator201012.loc[i, 'domain_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c00dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## wiki closure date\n",
    "(under construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5569af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_content_wikis = public_content_dbs.query(\"\"\"status == 'closed'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_content_wikis.git_closed_dt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d89f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_group_prefix_map = {'wikipedia': 'Wp',   \n",
    "                       'wikibooks': 'Wb',\n",
    "                       'wiktionary': 'Wt', \n",
    "                       'wikiquote': 'Wq', \n",
    "                       'wikisource': 'Ws',\n",
    "                       'wikinews': 'Wn',\n",
    "                       'wikivoyage': 'Wy',\n",
    "                       'wikiversity': 'Wv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd95cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prefix(db_group, language_code, prefix_map=db_group_prefix_map):\n",
    "    return f'{db_group_prefix_map[db_group]}/{language_code}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_content_wikis['prefix'] = closed_content_wikis[['database_group', 'language_code']].apply(lambda x:generate_prefix(x.database_group, x.language_code), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa150892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_log_query = \"\"\"\n",
    "WITH \n",
    "    logs AS (\n",
    "        SELECT \n",
    "            log_id,\n",
    "            log_timestamp,\n",
    "            log_title,\n",
    "            REGEXP_SUBSTR(log_title, 'W[a-z]/[a-z]+') AS prefix\n",
    "        FROM \n",
    "            logging\n",
    "        WHERE \n",
    "            log_type = 'import'\n",
    "        HAVING\n",
    "            REGEXP_SUBSTR(log_title, 'W[a-z]/[a-z]+') IN {CLOSED_DBS}),\n",
    "    \n",
    "    first_log AS (\n",
    "        SELECT\n",
    "            MIN(log_timestamp) AS log_timestamp,\n",
    "            prefix\n",
    "        FROM\n",
    "            logs\n",
    "        GROUP BY\n",
    "            prefix)\n",
    "    \n",
    "SELECT\n",
    "    prefix,\n",
    "    CONCAT(YEAR(log_timestamp), '-', MONTH(log_timestamp), '-', DAY(log_timestamp)) AS first_log_timestamp\n",
    "FROM \n",
    "    first_log\n",
    "\"\"\"\n",
    "\n",
    "incubator_import_log = wmf.mariadb.run(import_log_query.format(CLOSED_DBS=sql_tuple(closed_content_wikis.prefix.values)), dbs='incubatorwiki')\n",
    "incubator_import_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "incubator_import_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_content_wikis = pd.merge(closed_content_wikis, incubator_import_log, on='prefix', how='left')\n",
    "closed_content_wikis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45ba69-c89d-4de9-a5b7-5b4e9906f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_missing = closed_content_wikis[closed_content_wikis.first_log_timestamp.isna()]\n",
    "close_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee8e0d-4231-4816-bdf7-6ea270cba4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://meta.wikimedia.org/wiki/Stewards/Former_stewards')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd59afc-a115-445f-98a0-646b41530098",
   "metadata": {},
   "outputs": [],
   "source": [
    "former_stewards = pd.read_html(str(soup.find('table', {'class': 'sortable'})))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fbba8-0a44-4c9a-8aa2-cb8f28561fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_content_wikis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed8baf-9d79-4879-a368-dd27f947e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_stewards = wmf.mariadb.run(\"\"\"\n",
    "SELECT *\n",
    "FROM global_user_groups ug\n",
    "JOIN globaluser u\n",
    "ON u.gu_id = ug.gug_user\n",
    "WHERE gug_group = 'steward'\n",
    "\n",
    "\n",
    "\"\"\", ['centralauth'], use_x1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34107c61-cdeb-45a4-8b81-c88145e97ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stewards = former_stewards.Username.values.tolist() + current_stewards.gu_name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453c1dd-fd9e-4de8-b239-39d8597373cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stewards_sql = sql_tuple(stewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f62a3c-19d4-4e90-aa55-a2a1327592c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wmf.mariadb.run(f\"\"\"\n",
    "WITH max_time AS (SELECT MAX(rev_timestamp) AS timestamp\n",
    "FROM revision r\n",
    "JOIN actor a\n",
    "ON r.rev_actor = a.actor_id\n",
    "WHERE NOT (actor_name IN {stewards_sql} OR actor_name IN ('Flow talk page manager', 'Global rename script', 'MediaWiki message delivery', 'Maintenance script')))\n",
    "\n",
    "SELECT * FROM revision r\n",
    "JOIN actor a ON r.rev_actor = a.actor_id\n",
    "JOIN max_time m WHERE r.rev_timestamp = m.timestamp\n",
    "\n",
    "\n",
    "\"\"\", ['abwiktionary'])\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e33d12-41e2-45ec-a27f-36426a35a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df = wmf.mariadb.run(f\"\"\"\n",
    "SELECT *, MAX(rev_timestamp) AS timestamp\n",
    "FROM revision r\n",
    "JOIN actor a\n",
    "ON r.rev_actor = a.actor_id\n",
    "WHERE actor_name NOT IN {stewards_sql}\n",
    "\n",
    "\n",
    "\"\"\", close_missing.database_code.values.tolist())\n",
    "\n",
    "df['wiki_db'] = close_missing.database_code.values.tolist()\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daddc13-0b80-40f7-838c-4af941c5f8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f25824-53e0-4c01-b16d-088cc01defef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.actor_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4f782-5010-4e68-aa21-42c16b4f8dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
